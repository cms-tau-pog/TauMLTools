Setup:
    n_tau                :  250 # number of candidates in one batch 
    n_threads            :  1
    input_dir            : "/nfs/dust/cms/user/mykytaua/dataLLSTAU/tuples-tau-pog/HN_trilepton_M-4_tau/"
    output_classes       :  2
    dataloader_core      : "TauMLTools/Training/interface/DataLoaderReco_main.h"
    genLepton_geantMode  : -1 # 1-GeantMode, 2-Normal GenParticle collection
    include_mismatched   : False

SetupNN:
    model_name           : "TauRecoSNN"
    optimizer_name       : "Nadam"
    learning_rate        : 0.01
    n_batches            : -1
    n_batches_val        : -1
    n_batches_log        : 300
    epoch                : 0
    n_epochs             : 1
    validation_split     : 0.2
    max_queue_size       : 15
    n_load_workers       : 2
    mode                 : "p4"
    n_gnn_layers         : 6
    n_dim_gnn            : 2
    n_output_gnn         : 50
    n_output_gnn_last    : 30
    n_dense_layers       : 4
    n_dense_nodes        : 100
    wiring_mode          : "m3"
    dropout_rate         : 0
    regu_rate            : -1

CellObjectType : [ PfCand,  PfCandCategorical ] # All Cell Objects

# Embedded Cell Objects:
# For the features inside this group embedding will be used
# Embedding parameters will be taken from the cooresponding feature list:
# e.g: -> pfCand_particleType  : [ null, null, "categorical", 0, 8]
# cooresponding embedding parameters: -> tf.keras.layers.Embedding(8,  2)
EmbeddedCellObjectType : [ PfCandCategorical ]

SequenceLength:
    PfCand : 50
    PfCandCategorical : 50

Scaling_setup:
    # --------------------------------------------------------
    file_path: '/nfs/dust/cms/user/mykytaua/dataLLSTAU/tuples-tau-pog/HN_trilepton_M-4_tau/*.root' # input files to be used for computation of scaling params
    output_json_folder: 'output_json' # directory where json files with scaling params will be stored
    file_range: [0,10] # range of files in the sorted `file_path` to be processed, right endpoint excluded; -1 to run on all files from file_path
    tree_name: taus # TTree name in input files to be read
    log_step: 10 # will make a snapshot of scaling parameters per this number of input files
    version: 'Reco_UL2018_HNL_v1' # string to be added to a json filename

    # --------------------------------------------------------
    # aliases for selection cuts
    selection:
      - &mpi -3.141592653589793
      - &pi 3.141592653589793
      - &jet_valid 'jet_index >= 0'
      - &hasTrackDetails 'pfCand_hasTrackDetails == 1'
      - &dxy_error_valid '(pfCand_hasTrackDetails == 1) & ( pfCand_dxy_error < 1000.0 )' # check non-infinity of pfCand_dxy_error (normal distribution within 0.0-1.0)
      - &dz_error_valid '(pfCand_hasTrackDetails == 1) & ( pfCand_dz_error < 1000.0 )' # check non-infinity of pfCand_dz_error (normal distribution within 0.0-1.0)
      - &dz_valid '(pfCand_hasTrackDetails == 1) & ( pfCand_dz > -1000.0 ) & ( pfCand_dz < 1000.0 )'
      # - &hasTrackDetails_track_ndof '(pfCand_hasTrackDetails == 1)  & (pfCand_track_ndof > 0)'

        # parameters for inner/outer tau cones' definition
    cone_definition:
      null

    cone_selection:

      PfCand: 
        var_names:
          eta: pfCand_eta
          phi: pfCand_phi
        cone_types: [null]

      PfCandCategorical: 
        var_names:
          eta: pfCand_eta
          phi: pfCand_phi
        cone_types: [null]


Features_all :
    PfCand :
          - pfCand_pt                   : [ null, null, "linear", 0, 30 ]
          - pfCand_eta                  : [ null, null, "linear", -3.0, 3.0 ]
          - pfCand_phi                  : [ null, null, "linear", *mpi, *pi ]
          - pfCand_mass                 : [ null, null, "normal", -5, 5 ]
          - pfCand_charge               : [ null, null, "categorical" ]
          - pfCand_puppiWeight          : [ null, null, "no_scaling" ]
          - pfCand_puppiWeightNoLep     : [ null, null, "no_scaling" ]
          - pfCand_lostInnerHits        : [ null, null, "linear", 0, 10 ] # ???
          - pfCand_nPixelHits           : [ null, null, "linear", 0, 10 ]
          - pfCand_nHits                : [ null, null, "normal", -5, 5 ]
          - pfCand_hasTrackDetails      : [ null, null, "categorical" ]
          - pfCand_dxy                  : [ *hasTrackDetails, null, "normal", -5, 5 ]
          - pfCand_dxy_error            : [ *dxy_error_valid, null, "normal", -5, 5 ]
          - pfCand_dz                   : [ *dz_valid, null, "normal", -5, 5 ]
          - pfCand_dz_error             : [ *dz_error_valid, null, "normal", -5, 5 ]
          - pfCand_track_chi2           : [ *hasTrackDetails, null, "normal", -5, 5 ]
          - pfCand_track_ndof           : [ *hasTrackDetails, null, "normal", -5, 5 ]
          - pfCand_caloFraction         : [ null, null, "linear", 0.0, 1.0 ]
          - pfCand_hcalFraction         : [ null, null, "linear", 0.0, 1.0 ]
          - pfCand_rawCaloFraction      : [ null, null, "linear", 0.0, 2.6 ]
          - pfCand_rawHcalFraction      : [ null, null, "linear", 0.0, 1.0 ]
          - pfCand_valid                : [ null, null, "categorical"]
          - pfCand_px                   : [ null, null, "no_scaling" ]
          - pfCand_py                   : [ null, null, "no_scaling" ]
          - pfCand_pz                   : [ null, null, "no_scaling" ]
          - pfCand_E                    : [ null, null, "no_scaling" ]
          # - jet_eta                     : []
          # - jet_phi                     : []
          - pfCand_deta                 : [ *jet_valid, {"pfCand_ele_deta": "pfCand_eta - jet_eta"}, "no_scaling" ] #"linear", -1.0, 1.0]
          - pfCand_dphi                 : [ *jet_valid, {"pfCand_ele_dphi": "pfCand_phi - jet_eta"}, "no_scaling" ] #"linear", -1.0, 1.0]

    PfCandCategorical:
          - pfCand_particleType         : [ null, null, "categorical", 8, 2]
          - pfCand_pvAssociationQuality : [ null, null, "categorical", 8, 2]
          - pfCand_fromPV               : [ null, null, "categorical", 4, 2]

Features_disable :
    PfCand : [ ]
    PfCandCategorical : [ ]