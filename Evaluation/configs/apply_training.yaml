# will update baseline training cfg (retrieved from run artifacts) with these parameters
training_cfg_upd:
  Setup:
    n_tau: 250
    dataloader_core: "TauMLTools/Training/interface/DataLoader_main.h"
    debug: False
  SetupNN:
    n_batches: -1
    n_batches_val: -1
    validation_split: 0.
    max_queue_size: 1
    n_load_workers: 1

# mlflow info
path_to_mlflow: ???
experiment_id: ???
run_id: ???

# training/scaling cfg to init DataLoader class
path_to_training_cfg: ${path_to_mlflow}/${experiment_id}/${run_id}/artifacts/input_cfg/training_cfg.yaml
scaling_cfg: ${path_to_mlflow}/${experiment_id}/${run_id}/artifacts/input_cfg/ShuffleMergeSpectral_trainingSamples-2_files_0_498.json

# input path and file name
path_to_input_dir: ???
input_filename: null # without file extension

# output path and file name // will store prediction file in -> artifacts/predictions/{sample_alias}/{output_filename}.h5 
sample_alias: ??? 
output_filename: ${input_filename}_pred

# gpu setup
gpu_cfg: # for running on CPU specify "gpu_cfg: null" 
  gpu_mem  : 7 # in Gb
  gpu_index: 0

# misc.
verbose: True
checkout_train_repo: False # whether to checkout git commit used for running the training (fetched from artifacts)
