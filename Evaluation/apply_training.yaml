# will update baseline training cfg (retrieved from run artifacts) with these parameters
training_cfg_upd:
  Setup:
    n_tau: 1
    include_mismatched: True
  SetupNN:
    n_batches: -1
    n_batches_val: -1
    validation_split: 0.
    max_queue_size: 1
    n_load_workers: 1

# mlflow info
path_to_mlflow: ???
experiment_id: ???
run_id: ???

# training/scaling cfg to init DataLoader class
path_to_training_cfg: ${path_to_mlflow}/${experiment_id}/${run_id}/artifacts/input_cfg/training_cfg.yaml
scaling_cfg: ${path_to_mlflow}/${experiment_id}/${run_id}/artifacts/input_cfg/ShuffleMergeSpectral_trainingSamples-2_files_0_50.json

# input file for prediction
path_to_file: ??? 
file_alias: ??? # will be used in downstream modules for referencing this dataset

# gpu setup
gpu_cfg: # for running on CPU specify "gpu_cfg: null" 
  gpu_mem  : 7 # in Gb
  gpu_index: 0

# misc.
verbose: True
checkout_train_repo: True # whether to checkout git commit used for running the training (fetched from artifacts)
